{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc2de71",
   "metadata": {},
   "source": [
    "# 📗 01 — Prerequisites & Environment Setup\n",
    "\n",
    "> **Mission:** walk step‑by‑step through every installation and validation task required for this RAG workshop.  \n",
    "\n",
    "**Supported OS:** macOS (Apple & Intel) • Windows 10/11 • Linux (Ubuntu/Debian).  \n",
    "\n",
    "---\n",
    "\n",
    "### 🗺 Roadmap\n",
    "\n",
    "1. Check / install Python 3.11 +  \n",
    "2. Install Docker Desktop  \n",
    "3. Install fast tooling (`uv`, `ruff`)  \n",
    "4. Clone the course repo  \n",
    "5. Create & activate a virtual‑env  \n",
    "6. Install course dependencies  \n",
    "7. Pull & run services (OpenSearch + Dashboards + Ollama)  \n",
    "8. Create `constants.py`  \n",
    "9. Verify docTR OCR  \n",
    "10. Sanity‑check all services  \n",
    "\n",
    "*(Total hands‑on time: ≈ 25 minutes on a decent connection)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42334136",
   "metadata": {},
   "source": [
    "## 1 — Python 3.11 or newer 🐍\n",
    "\n",
    "Guide - https://realpython.com/installing-python/\n",
    "\n",
    "#### macOS\n",
    "\n",
    "```bash\n",
    "# Homebrew (recommended)\n",
    "brew install python@3.12\n",
    "echo 'export PATH=\"/opt/homebrew/opt/python@3.12/libexec/bin:$PATH\"' >> ~/.zshrc\n",
    "source ~/.zshrc\n",
    "\n",
    "which python3.12  \n",
    "python3 --version \n",
    "\n",
    "```\n",
    "#### Windows 10/11\n",
    "\n",
    "```powershell\n",
    "# Winget\n",
    "winget install Python.Python.3.12\n",
    "# OR Microsoft Store: \"Python 3.12\"\n",
    "\n",
    "python3 --version \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8aa11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2 — Install `uv`\n",
    "\n",
    "Document - https://docs.astral.sh/uv/getting-started/installation/#standalone-installer\n",
    "\n",
    "#### macOS / Linux (bash / zsh)\n",
    "\n",
    "```bash\n",
    "curl -LsSf https://astral.sh/uv/install.sh | less\n",
    "\n",
    "brew install uv \n",
    "```\n",
    "\n",
    "#### Windows (PowerShell)\n",
    "\n",
    "```powershell\n",
    "python3 -m pip install uv \n",
    "\n",
    "py -m pip install -U uv \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f88d4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.3 Create, Activate & Register a `uv` Kernel 🐍\n",
    "\n",
    "We will create an isolated environment for this course using `uv` and then register it as a kernel so Jupyter can use it.\n",
    "\n",
    "**Run these commands in your terminal**, from the `build_your_local_RAG_system` folder.\n",
    "\n",
    "#### 1.3.1 Create & Activate\n",
    "\n",
    "```bash\n",
    "# Create a virtual env using Python 3.12\n",
    "uv venv -p python3.12 .venv\n",
    "\n",
    "# Activate it (your prompt should get a (.venv) prefix)\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "> **Windows Users?**  \n",
    "> Use `.venv\\Scripts\\Activate.ps1` (PowerShell) or `.venv\\Scripts\\activate.bat` (CMD) to activate.\n",
    "\n",
    "#### 1.3.2 Install & Register Kernel\n",
    "\n",
    "```bash\n",
    "# Install the kernel package into our new env\n",
    "uv pip install ipykernel\n",
    "```\n",
    "\n",
    "#### 1.3.3 Select the Kernel in This Notebook\n",
    "\n",
    "**Restart your Jupyter server now.**\n",
    "\n",
    "Once it reloads, click here in the notebook and select from the top menu:\n",
    "\n",
    "`Kernel` → `Change kernel` → `RAG Course (Python 3.12)`\n",
    "\n",
    "After selecting it, the final check below should pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2b4bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"python_version\": \"3.12.11\",\n",
      "  \"ok\": true\n",
      "}\n",
      "Python version is sufficient\n"
     ]
    }
   ],
   "source": [
    "import sys, json\n",
    "py_ok = sys.version_info >= (3,11)\n",
    "print(json.dumps({\n",
    "    \"python_version\": sys.version.split()[0],\n",
    "    \"ok\": py_ok\n",
    "}, indent=2))\n",
    "assert py_ok, \"Python <3.11 — install a newer version before continuing\"\n",
    "print(\"Python version is sufficient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067044fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2 — Install Course Dependencies 📦\n",
    "\n",
    "```bash\n",
    "uv pip install -r requirements.txt               # main deps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58e4df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3 — Docker Desktop 🐳\n",
    "\n",
    "Download & install:\n",
    "\n",
    "* **macOS (Apple/Intel):** <https://www.docker.com/products/docker-desktop/>\n",
    "* **Windows 10/11:** same link (WSL 2 required)\n",
    "* **Linux:** `sudo apt install docker.io docker-compose-plugin`\n",
    "\n",
    "After installation **reboot** or at least restart your terminal so the `docker` command is on your PATH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd831ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"docker_cmd\": \"/usr/local/bin/docker\",\n",
      "  \"version\": \"Docker version 28.1.1, build 4eba377\"\n",
      "}\n",
      "✅ Docker CLI found\n"
     ]
    }
   ],
   "source": [
    "import subprocess, shutil, json\n",
    "docker_path = shutil.which(\"docker\")\n",
    "if not docker_path:\n",
    "    raise RuntimeError(\"🚨 'docker' command not found. Finish Docker install & restart terminal.\")\n",
    "ver = subprocess.check_output([\"docker\", \"--version\"], text=True)\n",
    "print(json.dumps({\"docker_cmd\": docker_path, \"version\": ver.strip()}, indent=2))\n",
    "print(\"✅ Docker CLI found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2cfea3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4 — Install Ollama\n",
    "\n",
    "Download & install:\n",
    "\n",
    "* https://ollama.com/download\n",
    "\n",
    "\n",
    "Lets download Qwen3 model:\n",
    "\n",
    "\n",
    "* https://ollama.com/library/qwen3\n",
    "\n",
    "```bash\n",
    "ollama run qwen3:8b \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc96046",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5 — Pull & Run Core Services \n",
    "\n",
    "### 5.1 OpenSearch (single‑node)\n",
    "\n",
    "```bash\n",
    "docker pull opensearchproject/opensearch:2.19.2\n",
    "docker pull opensearchproject/opensearch-dashboards:2.19.2\n",
    "\n",
    "docker run -d --name opensearch \\\n",
    "  -p 9200:9200 -p 9600:9600 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"DISABLE_SECURITY_PLUGIN=true\" \\\n",
    "  opensearchproject/opensearch:2.19.2\n",
    "\n",
    "docker run -d --name opensearch-dashboards \\\n",
    "  -p 5601:5601 \\\n",
    "  --link opensearch:opensearch \\\n",
    "  -e \"OPENSEARCH_HOSTS=http://opensearch:9200\" \\\n",
    "  -e \"DISABLE_SECURITY_DASHBOARDS_PLUGIN=true\" \\\n",
    "  opensearchproject/opensearch-dashboards:2.19.2\n",
    "```\n",
    "\n",
    "\n",
    "> Visit http://localhost:5601 in your browser to access the OpenSearch Dashboard. If you see the dashboard, you’re all set! 🎉\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc13be4",
   "metadata": {},
   "source": [
    "### 5.2 Add Hybrid functionality to OpenSearch\n",
    "\n",
    " > Open the OpenSearch Dashboard, go to Dev Tools, paste the below JSON, and hit Run. This pipeline will be essential for blending the BM25 and semantic scores for improved search quality.\n",
    "\n",
    "json\n",
    "```\n",
    "PUT /_search/pipeline/nlp-search-pipeline\n",
    "{\n",
    "  \"description\": \"Post processor for hybrid search\",\n",
    "  \"phase_results_processors\": [\n",
    "    {\n",
    "      \"normalization-processor\": {\n",
    "        \"normalization\": {\n",
    "          \"technique\": \"min_max\"\n",
    "        },\n",
    "        \"combination\": {\n",
    "          \"technique\": \"arithmetic_mean\",\n",
    "          \"parameters\": {\n",
    "            \"weights\": [\n",
    "              0.3,\n",
    "              0.7\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0da6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6 — Install and Verify OCR Engine (Tesseract)\n",
    "\n",
    "For our OCR tasks, we will use `pytesseract`, a Python wrapper for Google's Tesseract-OCR engine. This requires a two-part setup: first installing the engine on your operating system, and then installing the Python library that connects to it.\n",
    "\n",
    "### 6.1 Install External Dependencies (Tesseract & Poppler)\n",
    "\n",
    "`pytesseract` needs **Tesseract** to read characters, and its helper library `pdf2image` needs **Poppler** to convert PDF pages into images. You must install both.\n",
    "\n",
    "#### **macOS (via Homebrew)**\n",
    "\n",
    "Open your terminal and run this single command:\n",
    "```bash\n",
    "brew install tesseract poppler\n",
    "```\n",
    "\n",
    "#### **Windows**\n",
    "\n",
    "1.  **Install Tesseract:**\n",
    "    *   Download the official installer from the [Tesseract at UB Mannheim page](https://github.com/UB-Mannheim/tesseract/wiki).\n",
    "    *   Run the installer. **Important:** Take note of the installation path, which is usually `C:\\Program Files\\Tesseract-OCR`.\n",
    "    or\n",
    "    winget install Tesseract-OCR\n",
    "\n",
    "2.  **Install Poppler:**\n",
    "    *   Download the latest Poppler binary from [this GitHub repository](https://github.com/oschwartz/poppler-for-windows/releases/).\n",
    "    *   Unzip the file into a permanent location, like `C:\\poppler`.\n",
    "    *   Add the `bin` subfolder (e.g., `C:\\poppler\\poppler-24.02.0\\bin`) to your system's PATH environment variable.\n",
    "    Guide - https://github.com/oschwartz10612/poppler-windows/issues/42\n",
    "\n",
    "### 6.2 Install Python Libraries\n",
    "\n",
    "With the external tools installed, now install the Python libraries into your active virtual environment.\n",
    "\n",
    "```bash\n",
    "uv pip install pytesseract pdf2image Pillow fpdf2\n",
    "```\n",
    "> We install `fpdf2` just to create a dummy PDF for the test below.\n",
    "\n",
    "### 6.3 Run Verification Test\n",
    "\n",
    "The final step is to run the code cell below. It will:\n",
    "1.  Create a simple, one-page PDF file named `ocr_test.pdf`.\n",
    "2.  Use `pdf2image` and `pytesseract` to read the text from it.\n",
    "3.  Print the extracted text and a success message.\n",
    "\n",
    "> **Note for Windows Users:** You may need to uncomment and set the `tesseract_cmd` path in the code below if it's not found automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145c4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ac2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your PDF\n",
    "pdf_path = \"test.pdf\"\n",
    "\n",
    "# Convert PDF to images\n",
    "images = convert_from_path(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98354dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "2506.00233v1 [cs.AI] 30 May 2025\n",
      "\n",
      "arXiv\n",
      "\n",
      "Ethical AI: Towards Defining a Collective\n",
      "Evaluation Framework\n",
      "\n",
      "1“ Aasish Kumar Sharma\n",
      "Department of Computer Science\n",
      "Gottingent University\n",
      "Géttingen, Germany\n",
      "aasish-kumar.sharma @ gwdg.de\n",
      "\n",
      "NOTICE\n",
      "\n",
      "This work has been accepted for presentation at the 8th\n",
      "IEEE International Workshop on Advances in Artificial Intel-\n",
      "ligence and Machine Learning (AIML 2025): Futuristic AI and\n",
      "ML models & Intelligent Systems. © 2025 IEEE. Personal use\n",
      "of this material is permitted. The final published version will\n",
      "\n",
      "be available via IEEE Xplore at:\n",
      "\n",
      "Abstract—Artificial Intelligence (AI) is transforming sectors\n",
      "such as healthcare, finance, and autonomous systems, offering\n",
      "powerful tools for innovation. Yet its rapid integration raises\n",
      "urgent ethical concerns related to data ownership, privacy, and\n",
      "systemic bias. Issues like opaque decision-making, misleading\n",
      "outputs, and unfair treatment in high-stakes domains underscore\n",
      "the need for transparent and accountable AI systems.\n",
      "\n",
      "This article addresses these challenges by proposing a modular\n",
      "ethical assessment framework built on ontological blocks of mean-\n",
      "ing—discrete, interpretable units that encode ethical principles\n",
      "such as fairness, accountability, and ownership. By integrating\n",
      "these blocks with FAIR (Findable, Accessible, Interoperable,\n",
      "Reusable) principles, the framework supports scalable, transpar-\n",
      "ent, and legally aligned ethical evaluations, including compliance\n",
      "with the EU AI Act.\n",
      "\n",
      "Using a real-world use case in AI-powered investor profiling,\n",
      "the paper demonstrates how the framework enables dynamic,\n",
      "behavior-informed risk classification. The findings suggest that\n",
      "ontological blocks offer a promising path toward explainable and\n",
      "auditable AI ethics, though challenges remain in automation and\n",
      "probabilistic reasoning.\n",
      "\n",
      "Index Terms—Responsible AI, Ethical AI, Machine Ethics, AI\n",
      "Acts, Explainability, Ontology, Workflows, Transparency.\n",
      "\n",
      "I. INTRODUCTION\n",
      "\n",
      "Artificial Intelligence (AI) has emerged as a transformative\n",
      "technology, revolutionizing fields such as healthcare, finance,\n",
      "and autonomous systems. While AI offers significant benefits,\n",
      "including enhanced productivity and innovative solutions to\n",
      "global challenges, its rapid evolution also introduces profound\n",
      "ethical challenges that require immediate and thorough atten-\n",
      "tion.\n",
      "\n",
      "One of the foundational challenges lies in the data used to\n",
      "train AI systems. AI relies heavily on vast datasets sourced\n",
      "from the internet, private organizations, and other reposi-\n",
      "tories. However, issues related to data ownership, consent,\n",
      "and privacy remain unresolved. Questions such as ”Who\n",
      "\n",
      "24 Dimitar Kyosev\n",
      "Department of Legal Affairs\n",
      "Alis Grave Nil Private Limited\n",
      "Burgas, Bulgaria\n",
      "kyosev.dimitar @ gmail.com\n",
      "\n",
      "3% Julian Kunkel\n",
      "Faculty of Mathematics and Computer Science\n",
      "Georg-August-Universitat Gottingen\n",
      "Gottingen, Germany\n",
      "julian.kunkel @ gwdg.de\n",
      "\n",
      "owns the data?” and ”Was it ethically obtained?” highlight\n",
      "potential risks of misuse and exploitation, raising concerns\n",
      "about intellectual property rights and individual privacy.\n",
      "\n",
      "Another pressing issue is trustworthiness. AI systems oc-\n",
      "casionally produce misleading or incorrect outputs, a phe-\n",
      "nomenon known as “hallucinations.” Moreover, ensuring the\n",
      "safety of AI systems and maintaining detailed records of their\n",
      "decision-making processes are critical for fostering trust. With-\n",
      "out robust mechanisms for safety and accountability, reliance\n",
      "on AI systems could lead to unforeseen risks, particularly\n",
      "in high-stakes domains such as healthcare, finance, and law\n",
      "enforcement.\n",
      "\n",
      "However, the most profound challenges arise from the ethi-\n",
      "cal implications of AI’s outcomes. AI systems, often operating\n",
      "as “black boxes”, generate decisions and recommendations\n",
      "with far-reaching consequences. The absence of embedded\n",
      "ethical considerations can result in biased, unfair, or even\n",
      "harmful outcomes. For example:\n",
      "\n",
      "¢ Biased algorithms in hiring or lending processes can\n",
      "\n",
      "perpetuate societal inequalities.\n",
      "\n",
      "e Unethical use of AI in surveillance can infringe on civil\n",
      "\n",
      "liberties.\n",
      "\n",
      "e Lack of explainability can erode trust, particularly in life-\n",
      "\n",
      "critical applications.\n",
      "\n",
      "Addressing these challenges requires a collaborative effort\n",
      "among technologists, policymakers, ethicists, and the public.\n",
      "Establishing robust frameworks for ethical AI development\n",
      "and deployment is imperative to ensure AI aligns with human\n",
      "values and serves humanity equitably and responsibly.\n",
      "\n",
      "A. Key Ethical Challenges in AI\n",
      "\n",
      "e Data-Related Issues: These include questions around data\n",
      "accuracy, inclusion of purposefully misleading data or\n",
      "even data poisoning\n",
      "\n",
      "e Trustworthiness: Al systems must be reliable, safe, and\n",
      "explainable to avoid risks like hallucinations and over\n",
      "reliance on black-box outcomes.\n",
      "\n",
      "e Ethical Implications of Outcomes: The potential for bi-\n",
      "ased or harmful decisions underscores the need to embed\n",
      "ethical principles directly into AI systems.\n",
      "\n",
      "As AI continues to integrate into society, the task of address-\n",
      "\n",
      "ing these ethical dilemmas grows increasingly complex. While\n",
      "\n",
      "--- Page 2 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "the challenges are significant, they also present an opportunity\n",
      "to build a future where AI aligns with the highest ethical\n",
      "standards. By fostering collaboration and establishing com-\n",
      "prehensive frameworks, we can ensure that AI development\n",
      "progresses in a way that prioritizes transparency, fairness, and\n",
      "accountability.\n",
      "\n",
      "The article is organized in five sections: Introduction (Sec-\n",
      "tion[Ip, background (Section|fI), literature review (Section[IIp,\n",
      "methodology and discussion (Section |IV), then includes con-\n",
      "clusion and recommendations (Section |V).\n",
      "\n",
      "Il. BACKGROUND\n",
      "\n",
      "Ethical AI refers to the development and deployment o\n",
      "artificial intelligence systems that emphasize fairness, trans-\n",
      "parency, accountability, and respect for fundamental rights\n",
      "iy. AI ethics emphasises the impact of AI on individuals,\n",
      "groups and wider society. The goal is to promote safe an\n",
      "responsible AI use, to mitigate Al’s novel risks and prevent\n",
      "harm. Much of the work in this area centres around four main\n",
      "verticals: Frameworks such as the six core principles of the\n",
      "the EU AI Act highlight the importance o\n",
      "protecting autonomy, promoting equity, and fostering respon-\n",
      "sibility. Despite these efforts, ethical frameworks often lack\n",
      "technical grounding and do not address the dynamic nature o:\n",
      "AI systems [?], (i. (4-17).\n",
      "\n",
      "For example, Reinforcement-Learning (RL), particularly\n",
      "deep reinforcement learning, operates as a closed-box system,\n",
      "posing challenges in explainability (8}-(10}. Human-in-the-\n",
      "loop (HITL) AI approaches provide a potential solution\n",
      "by integrating human oversight at critical stages, but their im-\n",
      "plementation in Self Reinforcement Learning (SLR) remains\n",
      "limited.\n",
      "\n",
      "Recent studies highlight several state-of-the-art advances in\n",
      "ethical AI and SRL. Mehrabi et al. explore bias mitigation\n",
      "techniques such as data cleaning, model adjustments, and\n",
      "output tuning. (13). discusses interpretability approaches\n",
      "such as SHAP and LIME, which enhance explainability in\n",
      "complex models. Human-in-the-loop systems integrate\n",
      "ethical oversight effectively, while the EU AI Act offers\n",
      "risk-based regulations tailored for high-stakes applications.\n",
      "\n",
      "A. Objectives\n",
      "\n",
      "This article addresses key challenges in ethical AI and aims\n",
      "to:\n",
      "\n",
      "1) Propose a unified system for monitoring AI outcomes\n",
      "in line with the EU AI Act and emerging global regu-\n",
      "lations.\n",
      "\n",
      "2) Evaluate the feasibility of using ontological blocks of\n",
      "meaning for ethical assessment.\n",
      "\n",
      "3) Explore the integration of FAIR (Findable, Accessible,\n",
      "Interoperable, Reusable) principles into these ontologi-\n",
      "cal blocks.\n",
      "\n",
      "Together, these objectives support the development of ethi-\n",
      "cal AI frameworks that promote transparency, accountability,\n",
      "and fairness [15].\n",
      "\n",
      "III. LITERATURE REVIEW\n",
      "\n",
      "The rising importance of ethical Artificial Intelligence (AI)\n",
      "has driven researchers and institutions to develop frameworks,\n",
      "methods, and applications that promote transparency, account-\n",
      "ability, and fairness. This review is organized into subsections\n",
      "covering finance, healthcare, autonomous vehicles, ontological\n",
      "and FAIR approaches, and global initiatives.\n",
      "\n",
      "A. Ethical Al in Finance\n",
      "\n",
      "Al-driven credit scoring in finance raises ethical concerns\n",
      "about bias and unequal treatment.\n",
      "\n",
      "e Hassani shows how societal biases in training data\n",
      "reinforce discrimination in credit assessments, dispropor-\n",
      "tionately affecting marginalized groups.\n",
      "\n",
      "e Packin warns that lack of comprehensive data on\n",
      "disabled individuals can lead to exclusionary outcomes\n",
      "in Al-based scoring.\n",
      "\n",
      "Identified Gap: Independent tools like ontological blocks\n",
      "are proposed to detect and mitigate embedded bias in financial\n",
      "AI systems.\n",
      "\n",
      "B. Ethical Al in Healthcare\n",
      "\n",
      "Healthcare—particularly oncology—illustrates the need for\n",
      "ethical AI frameworks to safeguard privacy, transparency, and\n",
      "fairness [18].\n",
      "\n",
      "e Ontological blocks have been applied to sensitive patient\n",
      "data under FAIR principles, aiding in personalized treat-\n",
      "ment planning [19], (20).\n",
      "\n",
      "e Monteith et al. 21] caution against misinformation in AI\n",
      "mental health tools, stressing the need for explainability\n",
      "and oversight.\n",
      "\n",
      "e Antoniou et al. (22) highlight the need for explainable AI\n",
      "to manage complex diagnoses involving comorbidities.\n",
      "\n",
      "Identified Gap: Real-time, scalable use of explainable AI\n",
      "methods (e.g., SHAP, LIME) remains a key challenge in high-\n",
      "stakes clinical settings (8).\n",
      "\n",
      "C. Ethical AI in Autonomous Vehicles\n",
      "\n",
      "Autonomous vehicles demand AI systems that prioritize\n",
      "safety, accountability, and ethical reasoning.\n",
      "\n",
      "¢ Lin (23) and Jenkins et. al. [24] examines scenarios\n",
      "like the trolley problem, calling for transparent ethical\n",
      "decision-making in critical moments.\n",
      "\n",
      "e Goodall advocates for programming rules that min-\n",
      "imize harm during unavoidable accidents.\n",
      "\n",
      "e Nyholm and Smids argue for clear accountability\n",
      "frameworks among manufacturers, users, and regulators.\n",
      "\n",
      "Identified Gap: Ensuring real-time ethical decisions and\n",
      "system adaptability remains a core technical and ethical chal-\n",
      "lenge.\n",
      "\n",
      "--- Page 3 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "D. Ontological and FAIR Approaches for Ethical AI\n",
      "\n",
      "Ontological models and FAIR principles are emerging as\n",
      "\n",
      "foundational tools for ethical AI design.\n",
      "\n",
      "e Ontological blocks, drawing from Semantic Web stan-\n",
      "dards (27. (28), provide scalable representations of prin-\n",
      "ciples like non-maleficence and equity (2).\n",
      "\n",
      "¢ FAIR principles [6]—Findable, Accessible, Interoperable,\n",
      "and Reusable—support the openness and standardization\n",
      "of ethical modules.\n",
      "\n",
      "e Guizzardi et al. 29 emphasize the need for ontologies\n",
      "that model user-centric concerns like privacy, fairness,\n",
      "and risk.\n",
      "\n",
      "Challenges: Implementing FAIR-aligned ontological blocks\n",
      "\n",
      "is constrained by the manual effort needed to build and\n",
      "maintain interoperable frameworks.\n",
      "\n",
      "E. Global and Collaborative Efforts\n",
      "\n",
      "International collaborations aim to mitigate societal-scale\n",
      "risks and build governance frameworks for ethical AI 7. (30).\n",
      ".\n",
      "\n",
      "e The EU champions “ethics-by-design,’ embedding ethics\n",
      "at the development stage (6).\n",
      "\n",
      "« An international consortium proposes benchmarking so-\n",
      "cietal risks, promoting transparency and cooperative over-\n",
      "sight [32].\n",
      "\n",
      "e Responsible Research and Innovation (RRI) offers a\n",
      "governance model that aligns AI with societal values\n",
      "(33)-G7}.\n",
      "\n",
      "Future Direction: These efforts underscore the importance\n",
      "\n",
      "of global standards and shared accountability mechanisms for\n",
      "ethical AI deployment.\n",
      "\n",
      "IV. METHODOLOGY AND DISCUSSION\n",
      "A. Methodology\n",
      "\n",
      "This article uses descriptive research and qualitative obser-\n",
      "vation to explore ethical AI pathways. Key variables include:\n",
      "Ethical outcomes — Benchmarks set by experts in ethics, AI,\n",
      "and policy; Verification — Methods to automate assessments\n",
      "against those benchmarks; Scalability — Applicability across\n",
      "varied AI systems and domains.\n",
      "\n",
      "Rather than conducting empirical simulations, the study\n",
      "synthesizes literature, expert insights, and theoretical models\n",
      "to propose actionable frameworks.\n",
      "\n",
      "B. Flexibility Requirements for an Ethical AI\n",
      "\n",
      "Integrating ethical AI into legally binding decisions requires\n",
      "acknowledging that legal standards vary significantly by con-\n",
      "text. Ethical and legal thresholds are not fixed; they shift based\n",
      "on specific circumstances and competing interests. Therefore,\n",
      "ethical AI systems must be adaptable, aligning with legal\n",
      "norms while upholding fairness and accountability.\n",
      "\n",
      "For example, in serious criminal investigations like mur-\n",
      "der, authorities may justifiably relax privacy protections to\n",
      "prioritize truth-seeking over individual rights. In contrast,\n",
      "financial transactions—such as a custodian bank managing\n",
      "\n",
      "client funds—demand stricter ethical and legal adherence,\n",
      "emphasizing fiduciary duty over operational flexibility. These\n",
      "scenarios highlight the need for dynamic ethical standards that\n",
      "adjust to context.\n",
      "\n",
      "This variability challenges the one-size-fits-all ethics frame-\n",
      "works found in much of the AI literature, which often overlook\n",
      "the contextual nature of legal and ethical reasoning. An AI sys-\n",
      "tem cannot apply identical principles to a police investigation\n",
      "and a banking transaction, given their differing priorities and\n",
      "risks.\n",
      "\n",
      "We propose a flexible, modular framework based on onto-\n",
      "logical blocks of meaning—discrete ethical principles that\n",
      "can be layered or combined. This allows AI systems to\n",
      "dynamically tailor their ethical reasoning to specific legal\n",
      "domains. For instance, an AI analyzing financial data might\n",
      "prioritize fiduciary responsibility, while one used in criminal\n",
      "justice may focus on due process. Such a system ensures\n",
      "ethical adaptability, legal alignment, and transparent oversight.\n",
      "\n",
      "C. Ontological Blocks of Meaning\n",
      "\n",
      "Ontology—the philosophical study of definitions—offers\n",
      "a foundation for aligning human ethical concepts with AI\n",
      "systems. Just as the concept of light evolved from Newtonian\n",
      "particles to quantum duality, terms like responsibility or own-\n",
      "ership must be redefined for AI interpretation while preserving\n",
      "their ethical core.\n",
      "\n",
      "In AI ethics, this means translating abstract ethical\n",
      "terms—right, wrong, ownership, responsibility—into con-\n",
      "structs that AI can process. These must be both philosoph-\n",
      "ically robust and operationally viable. Ontological blocks are\n",
      "modular, structured representations of ethical principles that\n",
      "can be integrated into AI operations. Creating them involves:\n",
      "Translating ethical concepts into machine-readable constructs;\n",
      "Embedding them into modular, systematic representations;\n",
      "Preserving ethical meaning while ensuring scalability and\n",
      "precision.\n",
      "\n",
      "This ensures AI systems align with human values while\n",
      "providing a functional, auditable ethical framework.\n",
      "\n",
      "Practically, creating ontological blocks involves developing\n",
      "a structured system to categorize ethical principles, values,\n",
      "and guidelines. Drawing from ontological practices in fields\n",
      "like oncology—e.g., the Cancer Care Treatment Outcome\n",
      "Ontology and the NCI Thesaurus [19], [38]—this process\n",
      "starts by defining core ethical dimensions such as fairness,\n",
      "accountability, and transparency, and mapping them to relevant\n",
      "AI domains.\n",
      "\n",
      "Collaboration with domain experts ensures term accuracy\n",
      "and contextual relevance. Ethical AI frameworks such as those\n",
      "by Prem (13) support alignment with current standards. Recent\n",
      "models like the Ontology for Ethical AI Principles (AIPO) use\n",
      "vocabularies such as Dublin Core, SKOS, FOAF, and DCAT2\n",
      "to generate dynamic knowledge graphs, enabling semantic\n",
      "querying and systematic analysis (39). These approaches sup-\n",
      "port transparency, consistency, and accountability in ethical AI\n",
      "development.\n",
      "\n",
      "--- Page 4 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "hasConcept\n",
      "\n",
      "Ethical_Frameworks\n",
      "\n",
      "Core_Ethical_Concepts\n",
      "\n",
      "AI_Application_Areas\n",
      "\n",
      "Transparency\n",
      "\n",
      "hasSubConcept Accountability }\n",
      "\n",
      "rdf:type |-—>| Class | Data_Privacy\n",
      "\n",
      "Automated_Decision_Support\n",
      "\n",
      "Health_Care\n",
      "\n",
      "hasPrinciple } >| Ethical_AI_Principles\n",
      "\n",
      "hasExample\n",
      "\n",
      "Dublin_Core\n",
      "\n",
      "Fig. 1. An example of ontological block for ethical AI in RDF (Resource Description Framework) form\n",
      "¥ Human Oversight\n",
      "Data\n",
      "WA\n",
      "monitors\n",
      "Test\n",
      "(training data) Transparency monitors\n",
      "¥ requires\n",
      "y ensures V\n",
      "»\n",
      "Fairness > AI Decision Engine\n",
      "KKK .\n",
      "rN\n",
      "Block of Meaning Black Box includes\n",
      "A x forces\n",
      "y y enforces\n",
      "y ¥ Accountability\n",
      "Result Result .\n",
      "\" ., Privacy\n",
      "relivent relivent\n",
      "for all of the for the\n",
      "data testing data Fig. 3. Sketch: (b) Representation of ontological blocks for responsible AI.\n",
      "\n",
      "Fig. 2. Sketch: (a) Abstract view of ontological blocks processing for ethical\n",
      "frameworks.\n",
      "\n",
      "D. Designing Ontological Blocks for Algorithmic Use\n",
      "\n",
      "Ontological blocks translate ethical concepts into structured,\n",
      "quantifiable forms. For instance, defining “stealing is bad”\n",
      "involves breaking it down into core concepts like property\n",
      "and ownership.\n",
      "\n",
      "Example: A dataset element (e.g., a car) represents property,\n",
      "while ownership (e.g., “Tom owns the car’”’) provides context.\n",
      "Generalization: Instead of rule-based examples, AI evalu-\n",
      "ates principles of ownership, avoiding reliance on predefined\n",
      "scenarios. Incomplete data: Al may infer missing elements\n",
      "through cross-referencing. If cross-references are weak, hu-\n",
      "man oversight is required. Short format: The point of the\n",
      "ontological block is that it would refer a single concept (e.g.\n",
      "\n",
      "Each node represents a principle, and the relationships define their role in the\n",
      "AI system.\n",
      "\n",
      "ownership), therefore more complex ethical questions would\n",
      "be described as a sum of multiple ontological blocks.\n",
      "\n",
      "E. Common Structure of Ontological Blocks of Meaning\n",
      "\n",
      "A major challenge in ethical AI is ensuring ontological\n",
      "blocks follow a common structure to support uniform testing\n",
      "and consistent term relationships. The proposed structure is\n",
      "simple: a primary concept paired with a binary ethical qualifier\n",
      "(e.g., good or bad).\n",
      "\n",
      "For example, in the block “stealing is bad”, stealing is\n",
      "defined as the unauthorized transfer of ownership outside\n",
      "quantifiable pathways like trade, gift, bequest, or taxation.\n",
      "This format supports clear, consistent, and transparent ethical\n",
      "evaluations.\n",
      "\n",
      "--- Page 5 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "Block variables are selected by designers—researchers,\n",
      "practitioners, or stakeholders—ensuring both expert insight\n",
      "and public auditability. For complex concepts (e.g., medical\n",
      "emergency), multiple simpler blocks can be combined. This\n",
      "modular structure supports consistency and scalability across\n",
      "domains.\n",
      "\n",
      "These are the foundational principles that could guide\n",
      "visualizing ethical AI ontological block. They include:\n",
      "\n",
      "Fairness: Prevents bias and ensures equitable treatment. Ac-\n",
      "countability: Assigns responsibility for Al outcomes. Trans-\n",
      "parency: Promotes understandable, open AI processes AI\n",
      "Application Areas: Domains where ethical principles are\n",
      "applied. Ethical Frameworks: Structured sets of principles\n",
      "guiding ethical AI development.\n",
      "\n",
      "Together, these components provide a robust structure for\n",
      "designing ethical AI systems that are principled, transparent,\n",
      "and aligned with current standards.\n",
      "\n",
      "F. Pros and Cons of the Proposed Framework\n",
      "\n",
      "1) Advantages: Independence from training data, enabling\n",
      "robust ethical evaluations. Flexibility to combine blocks across\n",
      "fields, such as medicine or law. Auditability of standardized\n",
      "blocks, improving transparency and accountability.\n",
      "\n",
      "2) Drawbacks: — Labor-intensive creation of non-\n",
      "contradictory, quantifiable blocks. Reliance on large language\n",
      "models (LLMs) or external tools to infer missing relationships,\n",
      "introducing potential biases. Additional processing power\n",
      "required for integration and maintenance.\n",
      "\n",
      "Despite challenges, the framework’s flexibility, indepen-\n",
      "dence, and auditability make it a promising foundation for\n",
      "building ethically aligned AI systems.\n",
      "\n",
      "G. A Use-Case: Al-Powered CRM and Ontological Profiling\n",
      "for Investor Protection\n",
      "\n",
      "Overview: Brokerage firms are increasingly using AI-\n",
      "powered voice assistants to enhance investor classification and\n",
      "risk profiling. Moving beyond static binary systems, these\n",
      "tools enable more precise, ethical, and adaptive assessments of\n",
      "investor risk tolerance, protecting retail clients from unsuitable\n",
      "high-risk products [40].\n",
      "\n",
      "1) The Challenge: Regulations require firms to distinguish\n",
      "between professional and retail investors to prevent the latter\n",
      "from accessing high-risk instruments like synthetic options.\n",
      "However, current assessments often overlook real-world risk\n",
      "tolerance, especially under stress, leading to potential harm\n",
      "and regulatory noncompliance.\n",
      "\n",
      "2) The Innovation: This use case introduces ontological\n",
      "blocks of meaning for product classification. A financial prod-\n",
      "uct might trigger a “Riskier” block based on:\n",
      "\n",
      "- Financial risk — Potential economic loss.\n",
      "\n",
      "- Psychological risk — Emotional reaction to financial stress.\n",
      "\n",
      "This enables real-time, context-aware, and _ ethically\n",
      "grounded risk assessment.\n",
      "\n",
      "3) How It Works: AI voice assistants engage clients with\n",
      "adaptive questions (e.g., “How did you react to your last\n",
      "investment loss?”). A response like “Not well” may indicate\n",
      "emotional sensitivity. Using NLP and probabilistic modeling,\n",
      "the system estimates a behavioral risk profile.\n",
      "\n",
      "If there’s a high probability (e.g., 60%) of emotional\n",
      "vulnerability, a corresponding ontological block is triggered,\n",
      "ethically restricting access to high-risk products. This creates a\n",
      "personalized, behavior-informed investor classification frame-\n",
      "work.\n",
      "\n",
      "H. Discussion\n",
      "\n",
      "The evaluation shows that combining ontological blocks\n",
      "with FAIR principles offers a strong foundation for ethical\n",
      "AI monitoring. Key insights include:\n",
      "\n",
      "¢ The unified monitoring system effectively identifies eth-\n",
      "ical risks and supports compliance (e.g., EU AI Act).\n",
      "\n",
      "e Ontological blocks provide structured, modular, and in-\n",
      "terpretable ethical encoding.\n",
      "\n",
      "e FAIR principles enhance discoverability, usability, and\n",
      "scalability.\n",
      "\n",
      "Remaining challenges include the manual effort required\n",
      "to build blocks and the reliance on probabilistic reasoning\n",
      "with incomplete data. Future work should focus on automating\n",
      "block creation and improving data integration.\n",
      "\n",
      "V. CONCLUSION AND RECOMMENDATION\n",
      "\n",
      "This framework introduces ontological blocks as standard-\n",
      "ized, expert-designed tools for ethical AI assessment. These\n",
      "modular units enable transparent evaluations across diverse\n",
      "ethical contexts.\n",
      "\n",
      "Key strengths include independence from training data and\n",
      "flexibility across domains. However, challenges remain in\n",
      "automating block creation and managing dependencies on\n",
      "probabilistic models.\n",
      "\n",
      "By integrating with FAIR principles, the framework sup-\n",
      "ports ethical, transparent, and accountable AI systems—laying\n",
      "the groundwork for responsible AI development across sectors.\n",
      "\n",
      "ACKNOWLEDGMENT\n",
      "\n",
      "The authors sincerely thank theGesellschaft fiir wis-\n",
      "senschaftliche Datenverarbeitung mbH Gottingen (GWDG,\n",
      "Germany) for their valuable contributions. We are especially\n",
      "grateful for support from NHR|] essential for presenting this\n",
      "work, and appreciate the constructive feedback from our peers.\n",
      "This research was funded by the EU KISSKI Project under\n",
      "grant number 01—S22093A (Forderkennzeichen).\n",
      "\n",
      "REFERENCES\n",
      "\n",
      "{1] A. Jobin, M. Ienca, and E. Vayena, “The global landscape of ai\n",
      "ethics guidelines,’ Nature Machine Intelligence, vol. 1, no. 9, pp.\n",
      "\n",
      "389-399, 2019. [Online]. Available:\n",
      "s42256-019-0088-2\n",
      "\n",
      "http://www.nhr- verein.de/en/ourpartners\n",
      "\n",
      "--- Page 6 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "[2] A. A. Abujaber and A. J.\n",
      "\n",
      "B)\n",
      "\n",
      "Nashwan, “Ethical framework for\n",
      "artificial intelligence in healthcare research: A path to integrity,”\n",
      "World Journal of Methodology, vol. 14, no. 3, p. 94071, 9\n",
      "2024, pMID: 39310239; PMCID: PMC11230076. [Online]. Available:\n",
      "“Regulation (EU) 2024/1689 of the european parliament and of\n",
      "the council of 13 june 2024 laying down harmonised rules on\n",
      "artificial intelligence and amending regulations (EC) no 300/2008,\n",
      "(EU) no 167/2013, (EU) no 168/2013, (EU) 2018/858, (EU) 2018/1139\n",
      "and (EU) 2019/2144 and directives 2014/90/EU, (EU) 2016/797\n",
      "and (EU) 2020/1828 (artificial intelligence act) (text with EEA\n",
      "relevance),” legislative Body: CONSIL, EP. [Online]. Available:\n",
      "http://data.europa.eu/eli/reg/2024/1689/oj/eng\n",
      "\n",
      "N. Mika, G. Nadezhda, L. Jaana, and K. Raija, “Ethical ai for the\n",
      "governance of the society: Challenges and opportunities,” in CEUR\n",
      "Workshop Proceedings, vol. 2505, 2019, pp. 20-26. [Online]. Available:\n",
      "https://ceur- ws.org/Vol-2505/paper03.pdf\n",
      "\n",
      "N. Bostrom and E. Yudkowsky, “The ethics of artificial intelligence,”\n",
      "pp. 57-69, 2018, accessed: 2025-02-07. [Online]. Available:\n",
      "https://www.taylorfrancis.com/chapters/edit/10.1201/9781351251389-4/\n",
      "ethics-artificial-intelligence-nick- bostrom-eliezer- yudkowsky\n",
      "P. Brey and B. Dainow, “Ethics by design for artificial intelligence,”\n",
      "Al and Ethics, vol. 4, no. 4, pp. 1265-1277, 2024. [Online]. Available:\n",
      "https://link.springer.com/article/10.1007/s4368 1-023-00330-4\n",
      "\n",
      "A. B. Hanssen and S. Nichele, “Ethics of artificial intelligence\n",
      "demarcations,” Ethics in Information Technology, pp. 133-142,\n",
      "2019. [Online]. Available:\n",
      "978-3-030-35664-4_13\n",
      "\n",
      "P. Linardatos, V. Papastefanopoulos, and S. Kotsiantis, “Explainable AI:\n",
      "A review of machine learning interpretability methods,” vol. 23, no. 1,\n",
      "p. 18. [Online]. Available: |https://www.mdpi.com/1099-4300/23/1/18\n",
      "G. Vasan, Y. Wang, F. Shahriar, J. Bergstra, M. Jagersand, and A. R.\n",
      "Mahmood, “Revisiting sparse rewards for goal-reaching reinforcement\n",
      "learning,” arXiv preprint arXiv:2407.00324, 2024. [Online]. Available:\n",
      "https://arxiv.org/abs/2407.00324.\n",
      "\n",
      "S. Ibrahim, M. Mostafa, A. Jnadi, H. Salloum, and P. Osinenko,\n",
      "“Comprehensive overview of reward engineering and shaping in\n",
      "advancing reinforcement learning applications,” JEEE Access, vol. 12,\n",
      "pp. 175 473-175 500, 2024. [Online]. Available:\n",
      "\n",
      "org/document/10763475\n",
      "\n",
      "E. Mosqueira-Rey, E. Hernandez-Pereira, D. Alonso-Rios, J. Bobes-\n",
      "\n",
      "Bascaran, and A. Fernandez-Leal, “Human-in-the-loop machine\n",
      "learning: a state of the art,” Artificial Intelligence Review,\n",
      "vol. 56, no. 4, pp. 3005-3054, 4 2023. [Online]. Available:\n",
      "\n",
      "https://doi.org/10.1007/s10462-022-10246-w\n",
      "\n",
      "N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,\n",
      "“A survey on bias and fairness in machine learning,” ACM Computing\n",
      "Surveys (CSUR), vol. 54, no. 6, pp. 1-35, 2021. [Online]. Available:\n",
      "https://doi.org/10.1145/3457607\n",
      "\n",
      "E. Prem, “From ethical ai frameworks to tools: a review of approaches,”\n",
      "Al and Ethics, vol. 3, no. 3, pp. 699-716, 2023, accessed: 2025-02-07.\n",
      "{Online}. Available: ips. og/10.1007/+43681-023-00258-9)\n",
      "\n",
      "A. M. Salih, Z. Raisi-Estabragh, I. Boscolo Galazzo, P. Radeva, S. E.\n",
      "Petersen, K. Lekadir, and G. Menegaz. A perspective on explainable\n",
      "artificial intelligence methods: Shap and lime. [Online]. Available:\n",
      "https://arxiv.org/abs/2305.02012v3\n",
      "\n",
      "F. Rossi and N. Mattei, “Building ethically bounded ai,” Proceedings\n",
      "of the AAAI/ACM Conference on Al, Ethics, and Society, pp. 68-74,\n",
      "2018. [Online]. ‘Available: https/{doiorg/10.485S0/arXiv.1812.03980)\n",
      "B. K. Hassani, “Societal bias reinforcement through machine learning:\n",
      "a credit scoring perspective,” AJ and Ethics, vol. 1, no. 3, pp. 239-247,\n",
      "2021. [Online]. Available: http://dx.doi.org/10.2139/ssrn.362569 1\n",
      "\n",
      "N. G. Packin, “Disability discrimination using ai systems, social\n",
      "media and digital platforms: Can we disable digital bias?” Journal of\n",
      "International and Comparative Law, vol. 8, no. 2, pp. 487-512, 2021.\n",
      "[Online]. Available:\n",
      "id=3724556\n",
      "\n",
      "D. Talati, “Artificial intelligence (ai) in mental health diagnosis and\n",
      "treatment,” Journal of Knowledge Learning and Science Technol\n",
      "vol. 2, no. 3, pp. 251-2: 2023. [Online]. Available:\n",
      "//doi.org/10.6008 p253\n",
      "\n",
      "A. Kumar and B. Smith, “Oncology ontology in the nci thesaurus,”\n",
      "in Artificial Intelligence in Medicine: 10th Conference on Artificial\n",
      "Intelligence in Medicine, AIME 2005, Aberdeen, UK, July 23-27, 2005.\n",
      "\n",
      "https://papers.ssrn.com/sol3/papers.cfm?abstract_\n",
      "\n",
      "oo\n",
      "\n",
      "20)\n",
      "\n",
      "21\n",
      "\n",
      "22\n",
      "\n",
      "23\n",
      "\n",
      "24)\n",
      "\n",
      "25\n",
      "\n",
      "26\n",
      "\n",
      "27\n",
      "\n",
      "28\n",
      "\n",
      "29\n",
      "\n",
      "30)\n",
      "\n",
      "31\n",
      "\n",
      "32\n",
      "\n",
      "33\n",
      "\n",
      "34)\n",
      "\n",
      "35\n",
      "\n",
      "36\n",
      "\n",
      "37\n",
      "\n",
      "Proceedings 10, Springer. Springer, 2005, pp. 213-220. [Online].\n",
      "Available: https://link.springer.com/chapter/10.1007/11527770_30\n",
      "\n",
      "F. P. Lin, T. Groza, S. Kocbek, E. Antezana, and R. J. Epstein,\n",
      "“Cancer care treatment outcome ontology: a novel computable ontology\n",
      "for profiling treatment outcomes in patients with solid tumors,” JCO\n",
      "clinical cancer informatics, vol. 2, pp. 1-14, 2018. [Online]. Available:\n",
      "https://ascopubs.org/doi/pdf/10.1200/CCI.18.00026\n",
      "\n",
      "S. Monteith, T. Glenn, J. R. Geddes, P. C. Whybrow, E. Achtyes,\n",
      "and M. Bauer, “Artificial intelligence and increasing misinformation,”\n",
      "The British Journal of Psychiatry, vol. 224, no. 2, pp. 33-35, 2024.\n",
      "[Online]. Available:\n",
      "G. Antoniou, E. Papadakis, and G. Baryannis, “Mental health diagnosis:\n",
      "a case for explainable artificial intelligence,” International Journal\n",
      "on Artificial Intelligence Tools, vol. 31, no. 03, p. 2241003, 2022.\n",
      "(Online) Availabe: ipso. og/10.1 14318021821 3023410032)\n",
      "\n",
      "P. Lin, “Why ethics matters for autonomous cars,” Autonomous driving:\n",
      "Technical, legal and social aspects, pp. 69-85, 2016. [Online]. Available:\n",
      "\n",
      "https://link.springer.com/chapter/10.1007/978-3-662-45854-9 4\n",
      "\n",
      "R. Jenkins, D. Cerny, and T. Hribek, Autonomous vehicle ethics: the\n",
      "trolley problem and beyond. Oxford University Press, 2022. [Online].\n",
      "Available: tpsacademic.oup.combo0K/44058)\n",
      "\n",
      "N. J. Goodall, “Machine ethics and automated vehicles,”\n",
      "vehicle automation, pp. 93-102, 2014. [Online]. Available:\n",
      "S. Nyholm and J. Smids, “The ethics of accident-algorithms for\n",
      "self-driving cars: An applied trolley problem?” Ethical theory and\n",
      "moral practice, vol. 19, no. 5, pp. 1275-1289, 2016. [Online].\n",
      "Available: https://link.springer.com/article/10.1007/s10677-016-9745-2\n",
      "D. L. McGuinness, F. Van Harmelen ef al., “Owl web ontology\n",
      "language overview,’ W3C recommendation, vol. 10, no. 10, p.\n",
      "2004, 2004. [Online]. Available: https://static.twoday.net/7 ldesa1bif/\n",
      "G. Antoniou and F. v. Harmelen, “Web ontology language: Owl,”\n",
      "pp. 91-110, 2009. [Online]. Available:\n",
      "\n",
      "R. Guizzardi, G. Amaral, G. Guizzardi, and J. Mylopoulos, “An\n",
      "ontology-based approach to engineering ethicality requirements,”\n",
      "Software and Systems Modeling, vol. 22, no. 6, pp. 1897-1923,\n",
      "Jul. 2023. [Online]. Available:\n",
      "s10270-023-01115-3\n",
      "\n",
      "J. S. Roberts and L. N. Montoya, “Contextualizing artificially\n",
      "intelligent morality: A meta-ethnography of theoretical, political and\n",
      "applied ethics,” Journal of Artificial Intelligence Research, vol. 75, pp.\n",
      "482-501, 2022. [Online]. Available:\n",
      "R. Benjamins and I. Salazar, “Towards a framework for understanding\n",
      "societal and ethical implications of artificial intelligence,” CoRR, vol.\n",
      "al\n",
      "\n",
      "/2001.09750, 2020. [Online]. Available: https://arxiv.org/abs/2001.\n",
      "\n",
      "R. Gruetzemacher, A. Chan, K. Frazier, C. Manning, S. Los,\n",
      "J. Fox, J. Herndndez-Orallo, J. Burden, M. Franklin, C. N.\n",
      "Ghuidhir, M. Bailey, D. Eth, T. Pilditch, and K. Kilian, “An\n",
      "international consortium for evaluations of societal-scale risks from\n",
      "advanced ai,” Nov. 2023, arXiv:2310.14455 [cs]. [Online]. Available:\n",
      "\n",
      "http://arxiv.org/abs/2310.14455\n",
      "\n",
      "S. M. Field, J. Thompson, S. De Rijcke, B. Penders, and M. R. Munafo,\n",
      "“Exploring the dimensions of responsible research systems and cultures:\n",
      "a scoping review,” Royal Society Open Science, vol. 11, no. 1, p.\n",
      "230624, 2024. [Online]. Available: https://doi.org/10.1098/rsos.230624\n",
      "S. Ivanova, C. Reichetzer, A. Martinuzzi, F. Findler, and\n",
      "K. Miko-Schefzig, “Frames, interests, and incentives—a typology\n",
      "\n",
      "of institutionalizing ri in the business sector derived from\n",
      "ten pioneering projects,” Journal of Responsible Innovation,\n",
      "vol. 10, no. 1, p. 2267736, 2023. [Online]. Available:\n",
      "\n",
      "https://doi.org/10.1080/23299460.2023.2267736\n",
      "\n",
      "T. Volker, R. Slaattelid, and R. Strand, Translations of Responsibility:\n",
      "Innovation Governance in Three European Regions. Taylor &\n",
      "Francis, 2024. [Online]. Available: https://library.oapen.org/handle/20.\n",
      "H. Pacifico Silva, P. Lehoux, F. A. Miller, and J.-L. Denis, “Introducing\n",
      "responsible innovation in health: a policy-oriented framework,” Health\n",
      "\n",
      "--- Page 7 ---\n",
      "\n",
      "[Tesseract OCR]\n",
      "research policy and systems, vol. 16, pp. 1-13, 2018. [Online].\n",
      "Available: https://link.springer.com/article/10.1186/s12961-018-0362-5\n",
      "\n",
      "[38] W. Ceusters, B. Smith, and L. Goldberg, “A terminological and\n",
      "ontological analysis of the nci thesaurus,” Methods of information\n",
      "in medicine, vol. 44, no. 04, pp. 498-507, 2005, accessed: 2025-\n",
      "\n",
      "s:/]\n",
      "\n",
      "B9]\n",
      "\n",
      "[40] N. S. Egbuhuzor, A. J. Ajayi, E. E. igbe, O. O. 5\n",
      "C. P-M. Ewim, and D. I. Ajiga, “Ai and data-driven insights:\n",
      "Transforming customer relationship management (crm) in financial\n",
      "\n",
      "services,” Gulf Journal of Advance Business Research, vol. 3, no. 2, pp.\n",
      "\n",
      "483-511, 2025. [Online]. Available: https://link.springer.com/chapter/\n",
      "10.1007/978-3-031-28073-3_35\n"
     ]
    }
   ],
   "source": [
    "for i, img in enumerate(images):\n",
    "    print(f\"\\n--- Page {i+1} ---\\n\")\n",
    "    \n",
    "    # ----- Tesseract OCR -----\n",
    "    text_tesseract = pytesseract.image_to_string(img)\n",
    "    print(\"[Tesseract OCR]\")\n",
    "    print(text_tesseract.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
